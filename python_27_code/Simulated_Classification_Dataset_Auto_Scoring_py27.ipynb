{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import log_loss\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data & Models For Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"/Users/davidziganto/Repositories/Synthetic_Dataset_Generation/pickle_files/py27/X_test_py27.pkl\", 'rb') as picklefile: \n",
    "    X_test = pickle.load(picklefile)\n",
    "    \n",
    "with open(\"/Users/davidziganto/Repositories/Synthetic_Dataset_Generation/pickle_files/py27/y_test_py27.pkl\", 'rb') as picklefile: \n",
    "    y_test = pickle.load(picklefile)\n",
    "\n",
    "with open(\"/Users/davidziganto/Repositories/Synthetic_Dataset_Generation/pickle_files/py27/knn_needs_improvement_py27.pkl\", 'rb') as picklefile: \n",
    "    knn_needs_improvement = pickle.load(picklefile)\n",
    "    \n",
    "with open(\"/Users/davidziganto/Repositories/Synthetic_Dataset_Generation/pickle_files/py27/rf_satisfactory_py27.pkl\", 'rb') as picklefile: \n",
    "    rf_satisfactory = pickle.load(picklefile)\n",
    "\n",
    "with open(\"/Users/davidziganto/Repositories/Synthetic_Dataset_Generation/pickle_files/py27/gbc_proficient_py27.pkl\", 'rb') as picklefile: \n",
    "    gbc_proficient = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Log Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77172596402024607"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test, knn_needs_improvement.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57484754370751456"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test, rf_satisfactory.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54224558841354176"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test, gbc_proficient.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Pickle_Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_dict = {'knn':knn_needs_improvement, 'rf_':rf_satisfactory, 'gbc':gbc_proficient}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto_Score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def auto_score(pickle_dict):\n",
    "    '''\n",
    "    Input:\n",
    "        pickle_dict: dictionary where key is username | ID and value is model\n",
    "    Output:\n",
    "        username : [log loss value, classification] \n",
    "    '''\n",
    "    for k, v in pickle_dict.items():\n",
    "        score = round(log_loss(y_test, v.predict_proba(X_test)), 3)\n",
    "        if score < 0.57:\n",
    "            pickle_dict[k] = [score, \"Proficient\"]\n",
    "        elif score <= 0.60:\n",
    "            pickle_dict[k] = [score, \"Satisfactory\"]\n",
    "        else:\n",
    "            pickle_dict[k] = [score, \"Needs Improvement\"]\n",
    "            \n",
    "    return pickle_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gbc': [0.542, 'Proficient'],\n",
       " 'knn': [0.772, 'Needs Improvement'],\n",
       " 'rf_': [0.575, 'Satisfactory']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = auto_score(pickle_dict)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn 0.772 Needs Improvement\n",
      "rf_ 0.575 Satisfactory\n",
      "gbc 0.542 Proficient\n"
     ]
    }
   ],
   "source": [
    "for k,v in output.items():\n",
    "    print(k, output[k][0], output[k][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rationale For Scoring\n",
    "\n",
    "Default settings for KNN, Decision Trees, Logistic Regression, and Random Forest yield log loss values on the test set of 2.348, 13.276, 0.640, 0.608, respectively.\n",
    "\n",
    "The goal here is to determine each invidual's skill level in achieving performant modeling results. As such, it made sense to me to set the the threshold for *satisfactory* just below the lowest achievable value yielded by default model settings, which turned out to be 0.608 for random forest. A tuned random forest will produce a log loss less than 0.58 on the test set. \n",
    "\n",
    "Furthermore, in an attempt to separate the high-achieving students, a category called *proficient* is included. In order to achieve this status, a student must use modeling techniques either not covered or covered only very little detail to achieve the required log loss value. Therefore, the threshold (0.570) was set just below the log loss value of a tuned random forest (0.575). For instance, a tuned gradient boosted classifier can achieve a log loss of 0.542.\n",
    "\n",
    "**Note: There will be some variablity with inherently non-deterministic algorithms like random forest. The techniques will be the same but the results may vary slightly due to how the model was seeded.**\n",
    "\n",
    "**Note: This is a first attempt. Score thresholds can be adjusted as we collect data in our pilot program. In other words, this is a WIP.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
